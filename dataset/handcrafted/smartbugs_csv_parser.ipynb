{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reentrancy Metrics per Tool:\n",
      "==============================\n",
      "****************************************************************************************************\n",
      "Results for Solidity version: 0.8\n",
      "****************************************************************************************************\n",
      "Tool: ccc\n",
      "  Accuracy:  55.20\n",
      "  Precision: 58.33\n",
      "  Recall:    12.07\n",
      "  F1 Score:  20.00\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: confuzzius\n",
      "  Accuracy:  57.26\n",
      "  Precision: 53.97\n",
      "  Recall:    58.62\n",
      "  F1 Score:  56.20\n",
      "  Errors: 16.94\n",
      "------------------------------\n",
      "Tool: mythril-0.24.7\n",
      "  Accuracy:  71.20\n",
      "  Precision: 63.41\n",
      "  Recall:    89.66\n",
      "  F1 Score:  74.29\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: slither-0.11.3\n",
      "  Accuracy:  69.60\n",
      "  Precision: 67.86\n",
      "  Recall:    65.52\n",
      "  F1 Score:  66.67\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: solhint-6.0.0\n",
      "  Accuracy:  49.60\n",
      "  Precision: 27.27\n",
      "  Recall:    5.17\n",
      "  F1 Score:  8.70\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: oyente+-060ca34\n",
      "  Accuracy:  58.40\n",
      "  Precision: 53.85\n",
      "  Recall:    72.41\n",
      "  F1 Score:  61.76\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "****************************************************************************************************\n",
      "Results for Solidity version: 0.5\n",
      "****************************************************************************************************\n",
      "Tool: ccc\n",
      "  Accuracy:  62.81\n",
      "  Precision: 56.25\n",
      "  Recall:    81.82\n",
      "  F1 Score:  66.67\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: confuzzius\n",
      "  Accuracy:  57.85\n",
      "  Precision: 53.03\n",
      "  Recall:    63.64\n",
      "  F1 Score:  57.85\n",
      "  Errors: 15.70\n",
      "------------------------------\n",
      "Tool: conkas\n",
      "  Accuracy:  80.99\n",
      "  Precision: 76.67\n",
      "  Recall:    83.64\n",
      "  F1 Score:  80.00\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: mythril-0.24.7\n",
      "  Accuracy:  71.07\n",
      "  Precision: 62.50\n",
      "  Recall:    90.91\n",
      "  F1 Score:  74.07\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: slither-0.11.3\n",
      "  Accuracy:  69.42\n",
      "  Precision: 66.67\n",
      "  Recall:    65.45\n",
      "  F1 Score:  66.06\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: solhint-6.0.0\n",
      "  Accuracy:  50.41\n",
      "  Precision: 22.22\n",
      "  Recall:    3.64\n",
      "  F1 Score:  6.25\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: oyente+-060ca34\n",
      "  Accuracy:  80.99\n",
      "  Precision: 90.00\n",
      "  Recall:    65.45\n",
      "  F1 Score:  75.79\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "****************************************************************************************************\n",
      "Results for Solidity version: 0.4\n",
      "****************************************************************************************************\n",
      "Tool: ccc\n",
      "  Accuracy:  63.87\n",
      "  Precision: 56.63\n",
      "  Recall:    87.04\n",
      "  F1 Score:  68.61\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: confuzzius\n",
      "  Accuracy:  54.24\n",
      "  Precision: 50.00\n",
      "  Recall:    64.81\n",
      "  F1 Score:  56.45\n",
      "  Errors: 2.54\n",
      "------------------------------\n",
      "Tool: conkas\n",
      "  Accuracy:  78.99\n",
      "  Precision: 73.77\n",
      "  Recall:    83.33\n",
      "  F1 Score:  78.26\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: mythril-0.24.7\n",
      "  Accuracy:  70.59\n",
      "  Precision: 61.73\n",
      "  Recall:    92.59\n",
      "  F1 Score:  74.07\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: securify\n",
      "  Accuracy:  63.87\n",
      "  Precision: 57.53\n",
      "  Recall:    77.78\n",
      "  F1 Score:  66.14\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: sfuzz\n",
      "  Accuracy:  54.62\n",
      "  Precision: 50.00\n",
      "  Recall:    14.81\n",
      "  F1 Score:  22.86\n",
      "  Errors: 3.36\n",
      "------------------------------\n",
      "Tool: slither-0.11.3\n",
      "  Accuracy:  68.91\n",
      "  Precision: 65.45\n",
      "  Recall:    66.67\n",
      "  F1 Score:  66.06\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: solhint-6.0.0\n",
      "  Accuracy:  50.42\n",
      "  Precision: 22.22\n",
      "  Recall:    3.70\n",
      "  F1 Score:  6.35\n",
      "  Errors: 0.00\n",
      "------------------------------\n",
      "Tool: oyente+-060ca34\n",
      "  Accuracy:  81.51\n",
      "  Precision: 90.00\n",
      "  Recall:    66.67\n",
      "  F1 Score:  76.60\n",
      "  Errors: 0.00\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Read data from the CSV file and select only the required columns.\n",
    "filename = 'results_all_src.csv'\n",
    "\n",
    "if 'src' in filename:\n",
    "    out_csv = 'reentrancy_metrics_data_src.csv'\n",
    "    latex_file = 'latex_table_src.csv'\n",
    "else:\n",
    "    out_csv = 'reentrancy_metrics_data_bins.csv'\n",
    "    latex_file = 'latex_table_bins.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df = df[['filename', 'basename', 'exit_code', 'toolid', 'findings']]\n",
    "\n",
    "df['exit_code'] = df['exit_code'].fillna(-1).astype(int)\n",
    "#print(df.shape)\n",
    "df = df[~((df['toolid'] == 'ethor-2023') & (df['findings'] == '{}'))]\n",
    "df = df[df['basename'].str.contains('_safe|_ree', na=False)]\n",
    "\n",
    "#print(df.shape)\n",
    "# A dictionary mapping each tool to the string(s) it produces for a reentrancy finding.\n",
    "# You can easily update this dictionary as needed. For tools with multiple labels,\n",
    "# use a comma-separated string, e.g., 'tool_name': 'label1,label2'.\n",
    "reentrancy_labels = {\n",
    "    'ccc': 'Reentrancy_Vulnerability',\n",
    "    'confuzzius': 'Reentrancy',\n",
    "    'conkas': 'Reentrancy', #.sol 0.5\n",
    "    #'manticore-0.3.7': 'Reentrancy', # placeholder\n",
    "    'mythril-0.24.7': 'State_access_after_external_call_SWC_107',\n",
    "    'oyente+-2acaf2e': 'Re_Entrancy_Vulnerability',\n",
    "    'securify': 'DAO', \n",
    "    'securify2': 'Reentrancy', # does not work\n",
    "    'sfuzz': 'Reentrancy', \n",
    "    'slither-0.11.3': 'reentrancy_eth,reentrancy_no_eth',\n",
    "    #'smartcheck': 'Reentrancy', # never finds any occurrence of reentrancy\n",
    "    'solhint-6.0.0': 'reentrancy',\n",
    "    #'ethainter': 'Reentrancy', # does not work\n",
    "    'ethor-2023': 'insecure',\n",
    "    'oyente+-060ca34':'Re_Entrancy_Vulnerability',\n",
    "    'vandal': 'ReentrantCall',\n",
    "    'gpt-oss': 'reentrant',\n",
    "    'gpt-5-mini': 'reentrant',\n",
    "    'gpt-5': 'reentrant',\n",
    "    'gpt-5-nano': 'reentrant'\n",
    "    }\n",
    "\n",
    "# 1. Determine the \"true\" reentrancy label for each file based on its filename.\n",
    "# 'ree' followed by an optional number indicates a true reentrancy vulnerability.\n",
    "# df['true_reentrancy'] = df['filename'].str.contains(r'ree\\d*\\.sol', case=False)\n",
    "df['true_reentrancy'] = df['basename'].str.contains(r'_ree', case=False)\n",
    "\n",
    "# 2. Determine the \"predicted\" reentrancy label based on the 'findings' column.\n",
    "# This function will check if any of the tool-specific reentrancy labels are present in the findings.\n",
    "def get_prediction(row):\n",
    "    tool_id = row['toolid']\n",
    "    findings = str(row['findings']) # Convert to string to handle potential NaN values\n",
    "\n",
    "    # Check if the tool is in our labels dictionary.\n",
    "    if tool_id in reentrancy_labels:\n",
    "        # Split the tool's finding string into a list of individual labels.\n",
    "        tool_findings = [f.strip() for f in reentrancy_labels[tool_id].split(',')]\n",
    "        \n",
    "        # Check if any of the tool's labels are present in the findings from the data.\n",
    "        for label in tool_findings:\n",
    "            if label in findings:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df['predicted_reentrancy'] = df.apply(get_prediction, axis=1)\n",
    "#print(df['exit_code']==1)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a new CSV file.\n",
    "df.to_csv(out_csv, index=False)\n",
    "\n",
    "# 3. Calculate metrics for each unique tool and print only the results.\n",
    "# Analyze only the tools present in the reentrancy_labels dictionary.\n",
    "tools_to_analyze = reentrancy_labels.keys()\n",
    "\n",
    "print(\"Reentrancy Metrics per Tool:\")\n",
    "print(\"=\" * 30)\n",
    "versions = ['0_8', '0_5', '0_4']\n",
    "with open(latex_file, 'w') as latex_file:\n",
    "    \n",
    "    for version in versions:\n",
    "        latex_file.write('Solidity Version: ' + version.replace('_', '.') + '\\n')\n",
    "        latex_file.write('Tool,Accuracy,Precision,Recall,F1 Score,Errors\\n')\n",
    "        version_df = df[df['filename'].str.contains(version)]\n",
    "        print('*' * 100)\n",
    "        print('Results for Solidity version:', version.replace('_', '.'))\n",
    "        print('*' * 100)\n",
    "        for tool in tools_to_analyze:\n",
    "\n",
    "            # Filter the DataFrame for the current tool.\n",
    "            tool_df = version_df[version_df['toolid'] == tool]\n",
    "            n_results = tool_df.shape[0]\n",
    "            #if tool == 'vandal':\n",
    "                #print(tool_df)\n",
    "            #print(tool, tool_df.shape)\n",
    "            ERRORS = (tool_df['exit_code'] != 0).sum()\n",
    "            # if tool == 'vandal':\n",
    "            #     print(tool_df, tool_df.shape)\n",
    "            ERRORS2  = tool_df[(tool_df['exit_code'] != 0) & (tool_df['findings'] == '{}')].shape[0]/n_results if n_results >0 else 0\n",
    "            # Exclude rows where exit_code is not\n",
    "\n",
    "            \n",
    "\n",
    "            tool_df = tool_df[(tool_df['exit_code'] == '0') | ((tool_df['exit_code'] != 0) & tool_df['findings']!= '{}')]\n",
    "\n",
    "            #print( tool_df['findings'], tool_df['findings']!= '{}')\n",
    "            #tool_df = tool_df[tool_df['exit_code'] == '0']\n",
    "            # if tool == 'vandal':\n",
    "            #     print(tool_df, tool_df.shape)\n",
    "\n",
    "            # Calculate True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
    "            TP = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == True)])\n",
    "            FP = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == True)])\n",
    "            TN = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == False)])\n",
    "            FN = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == False)])\n",
    "            # print(TP, FP, TN, FN)\n",
    "            \n",
    "            # Calculate Accuracy, Precision, and Recall.\n",
    "            # Handle cases where the denominator is zero to avoid errors.\n",
    "            accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "            \n",
    "            # Precision: Out of all positive predictions, how many were correct?\n",
    "            precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "            \n",
    "            # Recall: Out of all actual positives, how many were correctly predicted?\n",
    "            recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "            # Calculate the F1 Score\n",
    "            f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            f1_score = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n",
    "            #f1_score = f1_score(tool_df['true_reentrancy'], tool_df['predicted_reentrancy'], zero_division=0, average = 'weighted')\n",
    "            if f1_score > 0:\n",
    "                latex_file.write(f'{tool},{accuracy*100:.2f},{precision*100:.2f},{recall*100:.2f},{f1_score*100:.2f},{ERRORS2*100:.2f}\\n')\n",
    "                print(f\"Tool: {tool}\")\n",
    "                print(f\"  Accuracy:  {accuracy*100:.2f}\")\n",
    "                print(f\"  Precision: {precision*100:.2f}\")\n",
    "                print(f\"  Recall:    {recall*100:.2f}\")\n",
    "                print(f\"  F1 Score:  {f1_score*100:.2f}\")\n",
    "                #print(f\"  Errors: {ERRORS}\")\n",
    "                print(f\"  Errors: {ERRORS2*100:.2f}\")\n",
    "                print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83971f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"reentrancy_metrics_data.csv\")\n",
    "\n",
    "# 1. Keep only rows where basename contains '_ree'\n",
    "df = df[df['basename'].str.contains('_ree', na=False)]\n",
    "\n",
    "# 2. Extract folder path from filename (everything except the last component)\n",
    "df['path'] = df['filename'].apply(lambda x: str(Path(x).parent))\n",
    "\n",
    "# 3. Compute TP, FP, FN, TN flags\n",
    "df['TP'] = (df['true_reentrancy'] & df['predicted_reentrancy'])\n",
    "df['FP'] = (~df['true_reentrancy'] & df['predicted_reentrancy'])\n",
    "df['FN'] = (df['true_reentrancy'] & ~df['predicted_reentrancy'])\n",
    "df['TN'] = (~df['true_reentrancy'] & ~df['predicted_reentrancy'])\n",
    "\n",
    "# 4. Aggregate by path and include total count\n",
    "agg = (\n",
    "    df.groupby('path')\n",
    "      .agg(\n",
    "          TP=('TP', 'sum'),\n",
    "          FP=('FP', 'sum'),\n",
    "          FN=('FN', 'sum'),\n",
    "          TN=('TN', 'sum'),\n",
    "          total_rows=('filename', 'count')\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 5. Save to CSV\n",
    "agg.to_csv(\"aggregated_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the CSV file and select only the required columns.\n",
    "df = pd.read_csv('results_all_bins.csv')\n",
    "df = df[['filename', 'exit_code', 'toolid', 'findings']]\n",
    "\n",
    "# A dictionary mapping each tool to the string(s) it produces for a reentrancy finding.\n",
    "# You can easily update this dictionary as needed. For tools with multiple labels,\n",
    "# use a comma-separated string, e.g., 'tool_name': 'label1,label2'.\n",
    "reentrancy_labels = {\n",
    "    'ccc': 'Reentrancy_Vulnerability',\n",
    "    'confuzzius': 'Reentrancy',\n",
    "    'conkas': 'Reentrancy', #.sol 0.5\n",
    "    #'manticore-0.3.7': 'Reentrancy', # placeholder\n",
    "    'mythril-0.24.7': 'State_access_after_external_call_SWC_107',\n",
    "    'oyente+-2acaf2e': 'Re_Entrancy_Vulnerability',\n",
    "    'securify': 'DAO', \n",
    "    'securify2': 'Reentrancy', # does not work\n",
    "    'sfuzz': 'Reentrancy', \n",
    "    'slither-0.11.3': 'reentrancy_eth,reentrancy_no_eth',\n",
    "    #'smartcheck': 'Reentrancy', # never finds any occurrence of reentrancy\n",
    "    'solhint-6.0.0': 'reentrancy',\n",
    "    #'ethainter': 'Reentrancy', # does not work\n",
    "    'ethor-2023': 'insecure',\n",
    "    'oyente+-060ca34':'Callstack_Depth_Attack_Vulnerability',\n",
    "    'vandal': 'ReentrantCall',\n",
    "    'gpt-oss': 'reentrant',\n",
    "    'gpt-5-mini': 'reentrant',\n",
    "    'gpt-5': 'reentrant',\n",
    "    'gpt-5-nano': 'reentrant'\n",
    "    }\n",
    "\n",
    "# 1. Determine the \"true\" reentrancy label for each file based on its filename.\n",
    "# 'ree' followed by an optional number indicates a true reentrancy vulnerability.\n",
    "# df['true_reentrancy'] = df['filename'].str.contains(r'ree\\d*\\.sol', case=False)\n",
    "df['true_reentrancy'] = df['filename'].str.contains(r'_ree', case=False)\n",
    "\n",
    "# 2. Determine the \"predicted\" reentrancy label based on the 'findings' column.\n",
    "# This function will check if any of the tool-specific reentrancy labels are present in the findings.\n",
    "def get_prediction(row):\n",
    "    tool_id = row['toolid']\n",
    "    findings = str(row['findings']) # Convert to string to handle potential NaN values\n",
    "    if tool_id == 'vandal':\n",
    "        print(findings)\n",
    "    # Check if the tool is in our labels dictionary.\n",
    "    if tool_id in reentrancy_labels:\n",
    "        # Split the tool's finding string into a list of individual labels.\n",
    "        tool_findings = [f.strip() for f in reentrancy_labels[tool_id].split(',')]\n",
    "        \n",
    "        # Check if any of the tool's labels are present in the findings from the data.\n",
    "        for label in tool_findings:\n",
    "            if label in findings:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "df['predicted_reentrancy'] = df.apply(get_prediction, axis=1)\n",
    "#print(df['exit_code']==1)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a new CSV file.\n",
    "df.to_csv('reentrancy_metrics_data.csv', index=False)\n",
    "\n",
    "# 3. Calculate metrics for each unique tool and print only the results.\n",
    "# Analyze only the tools present in the reentrancy_labels dictionary.\n",
    "tools_to_analyze = reentrancy_labels.keys()\n",
    "\n",
    "print(\"Reentrancy Metrics per Tool:\")\n",
    "print(\"=\" * 30)\n",
    "versions = ['0_8', '0_5', '0_4']\n",
    "\n",
    "for version in versions:\n",
    "    version_df = df[df['filename'].str.contains(version)]\n",
    "    print('*' * 100)\n",
    "    print('Results for Solidity version:', version.replace('_', '.'))\n",
    "    print('*' * 100)\n",
    "    for tool in tools_to_analyze:\n",
    "        \n",
    "        # Filter the DataFrame for the current tool.\n",
    "        tool_df = version_df[version_df['toolid'] == tool]\n",
    "        #print(tool, tool_df.shape)\n",
    "        ERRORS = (tool_df['exit_code'] != 0).sum()\n",
    "        tool_df = tool_df[tool_df['exit_code'] == 0]\n",
    "\n",
    "        # Calculate True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
    "        TP = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == True)])\n",
    "        FP = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == True)])\n",
    "        TN = len(tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == False)])\n",
    "        FN = len(tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == False)])\n",
    "\n",
    "        \n",
    "        # Calculate Accuracy, Precision, and Recall.\n",
    "        # Handle cases where the denominator is zero to avoid errors.\n",
    "        accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "        \n",
    "        # Precision: Out of all positive predictions, how many were correct?\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        \n",
    "        # Recall: Out of all actual positives, how many were correctly predicted?\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "        # Calculate the F1 Score\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        f1_score = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n",
    "        #f1_score = f1_score(tool_df['true_reentrancy'], tool_df['predicted_reentrancy'], zero_division=0, average = 'weighted')\n",
    "        if f1_score > 0:\n",
    "            print(f\"Tool: {tool}\")\n",
    "            print(f\"  Accuracy:  {accuracy*100:.2f}\")\n",
    "            print(f\"  Precision: {precision*100:.2f}\")\n",
    "            print(f\"  Recall:    {recall*100:.2f}\")\n",
    "            print(f\"  F1 Score:  {f1_score*100:.2f}\")\n",
    "            print(f\"  Errors: {ERRORS}\")\n",
    "            print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cefe7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Reentrancy Analysis per Tool and Category:\n",
      "============================================================\n",
      "Tool: ccc\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 365)\n",
      "    TP: 99\n",
      "    FP: 76\n",
      "    TN: 122\n",
      "    FN: 68\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 365\n",
      "Tool: confuzzius\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 317)\n",
      "    TP: 103\n",
      "    FP: 93\n",
      "    TN: 75\n",
      "    FN: 46\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 317\n",
      "Tool: conkas\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 240)\n",
      "    TP: 91\n",
      "    FP: 30\n",
      "    TN: 101\n",
      "    FN: 18\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 240\n",
      "Tool: mythril-0.24.7\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 26)\n",
      "    TP: 0\n",
      "    FP: 0\n",
      "    TN: 16\n",
      "    FN: 10\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 26\n",
      "Tool: oyente+-2acaf2e\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: securify\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 362)\n",
      "    TP: 41\n",
      "    FP: 30\n",
      "    TN: 167\n",
      "    FN: 124\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 362\n",
      "Tool: securify2\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: sfuzz\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 111)\n",
      "    TP: 7\n",
      "    FP: 6\n",
      "    TN: 53\n",
      "    FN: 45\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 111\n",
      "Tool: slither-0.11.3\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: solhint-6.0.0\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: ethor-2023\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: oyente+-060ca34\n",
      "------------------------------\n",
      "  Category: unknown (Total files: 105)\n",
      "    TP: 0\n",
      "    FP: 0\n",
      "    TN: 84\n",
      "    FN: 21\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 105\n",
      "Tool: vandal\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: gpt-oss\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: gpt-5-mini\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: gpt-5\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n",
      "Tool: gpt-5-nano\n",
      "------------------------------\n",
      "============================================================\n",
      "check if I counted correctly: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "\n",
    "def get_file_type(filename):\n",
    "    \"\"\"\n",
    "    Extracts the file type from the path using a predefined dictionary.\n",
    "    \"\"\"\n",
    "    d = {\n",
    "        'tests/0_8/cross-contract/create/': 'create',\n",
    "        'tests/0_8/cross-contract/gmx/': 'gmx',\n",
    "        'tests/0_8/cross-contract/human/': 'human',\n",
    "        'tests/0_8/cross-contract/read-only/': 'read-only',\n",
    "        'tests/0_8/cross-contract/to-target/': 'cross-to-target',\n",
    "        'tests/0_8/always-safe/underflow/': 'underflow',\n",
    "        'tests/0_8/always-safe/emit/': 'emit',\n",
    "        'tests/0_8/always-safe/constructor/': 'safe-constructor',\n",
    "        'tests/0_8/always-safe/send-transfer/': 'send-transfer',\n",
    "        'tests/0_8/always-safe/this/': 'safe-this',\n",
    "        'tests/0_8/cross-function/guard/mutex/mod/': 'cross-function-mod',\n",
    "        'tests/0_8/cross-function/guard/mutex/no-mod/': 'cross-function-mutex',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/': 'LLC-to-sender',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard/mutex/': 'LLC-to-sender-guard-mutex',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard/access-control/': 'LLC-to-sender-guard-access-control',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard/block-number/': 'LLC-to-sender-guard-block-number',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/folded': 'LLC-to-sender-folded',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/gas': 'LLC-to-sender-gas',\n",
    "        'tests/0_8/single-function/low-level-call/to-target/': 'LLC-to-target',\n",
    "        'tests/0_8/single-function/method-invocation/': 'single-cast'\n",
    "    }\n",
    "    cat = 'unknown'\n",
    "    for prefix, category in d.items():\n",
    "        if prefix in filename:\n",
    "            cat = category\n",
    "\n",
    "    return [cat]\n",
    "\n",
    "# 3. Analyze and print TP, FP, TN, FN for each tool and category.\n",
    "print(\"Detailed Reentrancy Analysis per Tool and Category:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for tool in reentrancy_labels.keys():\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    tool_df = df[df['toolid'] == tool].copy()\n",
    "    \n",
    "    # Store metrics for each category\n",
    "    category_metrics = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    total_contracts = 0\n",
    "    for _, row in tool_df.iterrows():\n",
    "        categories = get_file_type(row['filename'])\n",
    "        true_reentrancy = row['true_reentrancy']\n",
    "        predicted_reentrancy = row['predicted_reentrancy']\n",
    "\n",
    "        for category in categories:\n",
    "            if true_reentrancy and predicted_reentrancy:\n",
    "                category_metrics[category]['TP'] += 1\n",
    "            elif not true_reentrancy and predicted_reentrancy:\n",
    "                category_metrics[category]['FP'] += 1\n",
    "            elif not true_reentrancy and not predicted_reentrancy:\n",
    "                category_metrics[category]['TN'] += 1\n",
    "            elif true_reentrancy and not predicted_reentrancy:\n",
    "                category_metrics[category]['FN'] += 1\n",
    "            \n",
    "            category_metrics[category]['total'] += 1\n",
    "\n",
    "    for category, metrics in sorted(category_metrics.items()):\n",
    "        print(f\"  Category: {category} (Total files: {metrics['total']})\")\n",
    "        print(f\"    TP: {metrics['TP']}\")\n",
    "        print(f\"    FP: {metrics['FP']}\")\n",
    "        print(f\"    TN: {metrics['TN']}\")\n",
    "        print(f\"    FN: {metrics['FN']}\")\n",
    "        print(\"-\" * 30)\n",
    "    print(\"=\" * 60)\n",
    "    total_contracts += sum(metrics['total'] for metrics in category_metrics.values())\n",
    "    print('check if I counted correctly:', total_contracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b54a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: confuzzius\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: mythril-0.24.7\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: oyente+-2acaf2e\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: slither-0.11.3\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: solhint-6.0.0\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: oyente+-060ca34\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: vandal\n",
      "  False Positives:\n",
      "    No false positives found.\n",
      "  False Negatives:\n",
      "    No false negatives found.\n",
      "------------------------------\n",
      "Tool: gpt-oss\n",
      "  False Positives:\n",
      "    - cast: 1\n",
      "    - unknown: 4\n",
      "  False Negatives:\n",
      "    - guard: 1\n",
      "    - mod: 2\n",
      "    - mutex: 6\n",
      "    - no-mod: 4\n",
      "    - single-flag: 1\n",
      "    - to-sender: 1\n",
      "    - unknown: 7\n",
      "------------------------------\n",
      "Tool: gpt-5-mini\n",
      "  False Positives:\n",
      "    - folded: 1\n",
      "    - to-sender: 1\n",
      "    - unknown: 3\n",
      "  False Negatives:\n",
      "    - access-control: 1\n",
      "    - guard: 1\n",
      "    - mod: 2\n",
      "    - mutex: 3\n",
      "    - no-mod: 1\n",
      "    - to-sender: 1\n",
      "    - unknown: 7\n",
      "------------------------------\n",
      "Tool: gpt-5\n",
      "  False Positives:\n",
      "    - access-control: 1\n",
      "    - guard: 1\n",
      "    - to-sender: 1\n",
      "    - unknown: 1\n",
      "  False Negatives:\n",
      "    - access-control: 1\n",
      "    - cast: 3\n",
      "    - folded: 2\n",
      "    - guard: 1\n",
      "    - mod: 1\n",
      "    - mutex: 2\n",
      "    - no-mod: 1\n",
      "    - to-sender: 1\n",
      "    - unknown: 2\n",
      "------------------------------\n",
      "Tool: gpt-5-nano\n",
      "  False Positives:\n",
      "    - cast: 2\n",
      "    - folded: 1\n",
      "    - gas: 1\n",
      "    - to-sender: 1\n",
      "    - unknown: 6\n",
      "  False Negatives:\n",
      "    - mod: 2\n",
      "    - mutex: 5\n",
      "    - no-mod: 3\n",
      "    - unknown: 6\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def get_file_type(filename):\n",
    "\n",
    "    d = {\n",
    "        'tests/0_8/cross-contract/create/': 'create',\n",
    "        'tests/0_8/cross-contract/gmx/': 'gmx',\n",
    "        'tests/0_8/cross-contract/human/': 'human',\n",
    "        'tests/0_8/cross-contract/read-only/': 'read-only',\n",
    "        'tests/0_8/cross-contract/to-target/': 'cross-to-target',\n",
    "        'tests/0_8/always-safe/underflow/': 'underflow',\n",
    "        'tests/0_8/always-safe/emit/': 'emit',\n",
    "        'tests/0_8/always-safe/constructor/': 'safe-constructor',\n",
    "        'tests/0_8/always-safe/send-transfer/': 'send-transfer',\n",
    "        'tests/0_8/always-safe/this/': 'safe-this',\n",
    "        'tests/0_8/cross-function/guard/mutex/mod/': 'cross-function-mod',\n",
    "        'tests/0_8/cross-function/guard/mutex/no-mod/': 'cross-function-mutex',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/': 'LLC-to-sender',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/guard': 'LLC-to-sender-guard',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/folded': 'LLC-to-sender-folded',\n",
    "        'tests/0_8/single-function/low-level-call/to-sender/gas': 'LLC-to-sender-gas',\n",
    "        'tests/0_8/single-function/low-level-call/to-target/': 'LLC-to-target',\n",
    "        'tests/0_8/single-function/method-invocation/': 'single-cast'\n",
    "    }\n",
    "    cat = 'unknown'\n",
    "    for prefix, category in d.items():\n",
    "        if prefix in filename:\n",
    "            cat = category\n",
    "\n",
    "    return [cat]\n",
    "\n",
    "\n",
    "for tool in tools_to_analyze:\n",
    "    tool_df = df[df['toolid'] == tool]\n",
    "\n",
    "    # Analyze False Positives (FP)\n",
    "    false_positives = tool_df[(tool_df['true_reentrancy'] == False) & (tool_df['predicted_reentrancy'] == True)]\n",
    "    fp_categories = defaultdict(int)\n",
    "    for _, row in false_positives.iterrows():\n",
    "        categories = get_file_type(row['filename'])\n",
    "        for cat in categories:\n",
    "            fp_categories[cat] += 1\n",
    "    \n",
    "    # Analyze False Negatives (FN)\n",
    "    false_negatives = tool_df[(tool_df['true_reentrancy'] == True) & (tool_df['predicted_reentrancy'] == False)]\n",
    "    fn_categories = defaultdict(int)\n",
    "    for _, row in false_negatives.iterrows():\n",
    "        categories = get_file_type(row['filename'])\n",
    "        for cat in categories:\n",
    "            fn_categories[cat] += 1\n",
    "\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(\"  False Positives:\")\n",
    "    if fp_categories:\n",
    "        for cat, count in sorted(fp_categories.items()):\n",
    "            print(f\"    - {cat}: {count}\")\n",
    "    else:\n",
    "        print(\"    No false positives found.\")\n",
    "    \n",
    "    print(\"  False Negatives:\")\n",
    "    if fn_categories:\n",
    "        for cat, count in sorted(fn_categories.items()):\n",
    "            print(f\"    - {cat}: {count}\")\n",
    "    else:\n",
    "        print(\"    No false negatives found.\")\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
