{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-07T14:34:03.950150Z",
     "start_time": "2025-09-07T14:34:03.931461Z"
    }
   },
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Configuration ---\n",
    "# Specify a list of input CSV files to process.\n",
    "INPUT_FILES: List[Path] = [\n",
    "    Path('results_handcrafted_0_8_source_llm.csv'),\n",
    "    Path('results_handcrafted_0_8_source.csv'),\n",
    "    Path('results_handcrafted_0_5_source.csv'),\n",
    "    Path('results_handcrafted_0_4_source.csv'),\n",
    "    Path('results_handcrafted_0_8_bin.csv'),\n",
    "    Path('results_handcrafted_0_5_bin.csv'),\n",
    "    Path('results_handcrafted_0_4_bin.csv'),\n",
    "]\n",
    "OUTPUT_FILE = Path('reentrancy_metrics_data_combined.csv')\n",
    "COLUMNS_TO_USE = ['filename', 'toolid', 'findings']\n",
    "HIERARCHICAL_MAX_DEPTH = 30\n",
    "\n",
    "# A dictionary mapping each tool to its label(s) for a reentrancy finding.\n",
    "REENTRANCY_LABELS: Dict[str, str] = {\n",
    "    'ccc': 'Reentrancy_Vulnerability',\n",
    "    'confuzzius': 'Reentrancy',\n",
    "    'conkas': 'Reentrancy',\n",
    "    'mythril-0.24.7': 'State_access_after_external_call_SWC_107',\n",
    "    'oyente+-2acaf2e': 'Re_Entrancy_Vulnerability',\n",
    "    'securify': 'DAO',\n",
    "    'sfuzz': 'Reentrancy',\n",
    "    'slither-0.11.3': 'reentrancy_eth,reentrancy_no_eth',\n",
    "    'solhint-6.0.0': 'reentrancy',\n",
    "    'ethor-2023': 'insecure',\n",
    "    'oyente+-060ca34': 'Callstack_Depth_Attack_Vulnerability',\n",
    "    'vandal': 'ReentrantCall',\n",
    "    'gpt-oss': 'reentrant',\n",
    "    'gpt-5-mini': 'reentrant',\n",
    "    'gpt-5': 'reentrant',\n",
    "    'gpt-5-nano': 'reentrant'\n",
    "}\n",
    "\n",
    "\n",
    "# --- Functions ---\n",
    "\n",
    "def log(message: str, level: str = \"INFO\"):\n",
    "    \"\"\"Prints a formatted log message with a timestamp.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{level}] [{timestamp}] {message}\")\n",
    "\n",
    "\n",
    "def load_and_prepare_data(filepath: Path, use_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads data from a list of CSVs, checks for a 'fails' column,\n",
    "    and prepares the DataFrame for analysis.\n",
    "    \"\"\"\n",
    "    log(\"Loading data...\")\n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        log(f\"--> Reading '{filepath}'\")\n",
    "        all_cols = pd.read_csv(filepath, nrows=0).columns.tolist()\n",
    "        cols_to_read = use_cols[:]\n",
    "        if 'fails' in all_cols:\n",
    "            cols_to_read.append('fails')\n",
    "\n",
    "        df = pd.read_csv(filepath, usecols=cols_to_read)\n",
    "        df_copy = df.copy()\n",
    "        for i, row in df_copy.iterrows():\n",
    "            if not any(row['toolid'] in x for x in REENTRANCY_LABELS.keys()):\n",
    "                df = df.drop(i)\n",
    "\n",
    "        if 'fails' not in df.columns:\n",
    "            df['fails'] = \"{}\"\n",
    "        else:\n",
    "            df['fails'] = df['fails'].fillna(\"{}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        log(f\"File not found at '{filepath}'. Skipping.\", level=\"WARN\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        log(f\"Could not read file '{filepath}'. Error: {e}. Skipping.\", level=\"WARN\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df['true_reentrancy'] = df['filename'].str.contains(r'_ree', case=False)\n",
    "    df['findings'] = df['findings'].fillna('').astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_predictions(df: pd.DataFrame, labels_map: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a 'predicted_reentrancy' column based on tool findings.\n",
    "    \"\"\"\n",
    "    processed_labels = {tool: labels.split(',') for tool, labels in labels_map.items()}\n",
    "\n",
    "    def get_prediction(row: pd.Series) -> bool:\n",
    "        tool_labels = processed_labels.get(row['toolid'])\n",
    "        if not tool_labels:\n",
    "            return False\n",
    "        return any(label.strip() in row['findings'] for label in tool_labels)\n",
    "\n",
    "    df['predicted_reentrancy'] = df.apply(get_prediction, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_metrics_for_group(group: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculates confusion matrix and metrics, accounting for failed runs\n",
    "    as misclassifications.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(group) != group.filename.unique().shape[0]:\n",
    "        agg_rules = {\n",
    "            \"fails\": lambda x: \" \".join(map(str, sorted(set(x)))),\n",
    "            \"predicted_reentrancy\": \"max\",\n",
    "            \"true_reentrancy\": \"max\"\n",
    "        }\n",
    "\n",
    "        group = group.groupby(\"filename\", as_index=False).agg(agg_rules)\n",
    "\n",
    "    failed_runs = group['fails'] != \"{}\"\n",
    "    num_fails = failed_runs.sum()\n",
    "\n",
    "    fn_from_fails = (group.loc[failed_runs, 'true_reentrancy'] == True).sum()\n",
    "    fp_from_fails = (group.loc[failed_runs, 'true_reentrancy'] == False).sum()\n",
    "\n",
    "    non_failed_group = group[~failed_runs]\n",
    "    tp = ((non_failed_group['true_reentrancy'] == True) & (non_failed_group['predicted_reentrancy'] == True)).sum()\n",
    "    tn = ((non_failed_group['true_reentrancy'] == False) & (non_failed_group['predicted_reentrancy'] == False)).sum()\n",
    "    fp = ((non_failed_group['true_reentrancy'] == False) & (non_failed_group['predicted_reentrancy'] == True)).sum()\n",
    "    fn = ((non_failed_group['true_reentrancy'] == True) & (non_failed_group['predicted_reentrancy'] == False)).sum()\n",
    "\n",
    "    fp += fp_from_fails\n",
    "    fn += fn_from_fails\n",
    "\n",
    "    accuracy = ((tp + tn) / (tp + fp + tn + fn)) if (tp + fp + tn + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return pd.Series({\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1_Score': f1_score,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'Fails': num_fails,\n",
    "        'Count': len(group)\n",
    "    })\n",
    "\n",
    "\n",
    "def calculate_and_display_metrics(df: pd.DataFrame):\n",
    "    \"\"\"Calculates and displays metrics for each source input file.\"\"\"\n",
    "    log(\"=\" * 50)\n",
    "    log(\"Reentrancy Metrics:\")\n",
    "    log(\"=\" * 50)\n",
    "\n",
    "    tool_metrics = df.groupby('toolid').apply(calculate_metrics_for_group, include_groups=False)\n",
    "    reportable_metrics = tool_metrics[tool_metrics['F1_Score'] > 0].sort_index()\n",
    "\n",
    "    for tool, data in reportable_metrics.iterrows():\n",
    "        print(f\"  Tool: {tool}\")\n",
    "        print(f\"    Accuracy: {data['Accuracy']:.2f}\")\n",
    "        print(f\"    Precision: {data['Precision']:.2f}\")\n",
    "        print(f\"    Recall:    {data['Recall']:.2f}\")\n",
    "        print(f\"    F1 Score:  {data['F1_Score']:.2f}\")\n",
    "        if 'Fails' in data and data['Fails'] > 0:\n",
    "            print(f\"    Fails:     {int(data['Fails'])}\")\n",
    "\n",
    "\n",
    "def filename2dirname(filename: str) -> Path:\n",
    "    path = Path(filename)\n",
    "    filename = path.parts[-1]\n",
    "    if filename.endswith(\".hex\") and len(path.parts) > 1:\n",
    "        path = path.parent\n",
    "    path_components = path.parts\n",
    "    filename_path = path_components[-1].split(\"_sol_\")[0]\n",
    "    filename_components = filename_path.split('_')\n",
    "    filename = '_'.join(filename_components[-2:]).split('.')[0]\n",
    "    path = Path(\"/\".join(list(path_components[:-1]) + filename_components[:-2] + [filename]))\n",
    "    path = path.parent\n",
    "    return path\n",
    "\n",
    "\n",
    "def clean_filename(filename: str) -> str:\n",
    "    path = Path(filename)\n",
    "    if filename.endswith(\".hex\") and len(path.parts) > 1:\n",
    "        return path.parts[-2]\n",
    "    path_components = path.parts\n",
    "    filename_path = path_components[-1].split(\"_sol_\")[0]\n",
    "    filename_components = filename_path.split('_')\n",
    "    filename = '_'.join(filename_components[-2:]).split('.')[0]\n",
    "    return filename\n"
   ],
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:34:03.965100Z",
     "start_time": "2025-09-07T14:34:03.955256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_metrics_by_path_and_version(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Aggregates metrics per directory path, solidity version, and toolid.\n",
    "    Returns two dataframes: one for source, one for binary.\n",
    "    \"\"\"\n",
    "    # Add helper cols\n",
    "    df['directory'] = df['filename'].apply(lambda f: str(filename2dirname(f)))\n",
    "    df.filename = df.filename.apply(clean_filename)\n",
    "    df.drop(columns=['findings'], inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    grouped = (\n",
    "        df.groupby(['type', 'directory', 'solidity_version', 'toolid'])\n",
    "        .apply(calculate_metrics_for_group, include_groups=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    source_df = grouped[grouped['type'] == \"source\"].drop(columns=[\"type\"])\n",
    "    bin_df = grouped[grouped['type'] == \"bin\"].drop(columns=[\"type\"])\n",
    "    return source_df, bin_df\n",
    "\n",
    "\n",
    "def display_path_version_tables(source_df: pd.DataFrame, bin_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Pretty-prints two final tables (source vs bin), grouped by directory and solidity version.\n",
    "    \"\"\"\n",
    "\n",
    "    def display_table(df: pd.DataFrame, title: str):\n",
    "        log(\"=\" * 70)\n",
    "        log(f\"{title}\")\n",
    "        log(\"=\" * 70)\n",
    "        for directory in sorted(df['directory'].unique()):\n",
    "            dir_df = df[df['directory'] == directory]\n",
    "            print(f\"\\nðŸ“‚ Path: {directory} - N={int(dir_df.iloc[0]['Count'])}\")\n",
    "            row_str = []\n",
    "            for tool in sorted(dir_df[\"toolid\"].unique()):\n",
    "                for input_type in sorted(dir_df[\"input\"].unique()):\n",
    "                    prefix = f\"    - Tool ({input_type}): {tool:<20} | \"\n",
    "                    tool_df = dir_df[(dir_df['toolid'] == tool) & (dir_df['input'] == input_type)]\n",
    "                    empty_count = 0\n",
    "                    for version in sorted(dir_df['solidity_version'].unique()):\n",
    "                        version_df = tool_df[tool_df['solidity_version'] == version]\n",
    "                        if version_df.empty:\n",
    "                            empty_count += 1\n",
    "                            version_result = f\"v{version} -- A: -, TP: -, TN: -, FP: -, FN: -, Fails: -\"\n",
    "                        else:\n",
    "                            row = version_df.iloc[0]\n",
    "                            version_result = f\"v{version} -- A: {row['Accuracy']:.2f}, TP: {int(row['TP'])}, TN: {int(row['TN'])}, FP: {int(row['FP'])}, FN: {int(row['FN'])}, Fails: {int(row['Fails'])}\"\n",
    "                        row_str.append(version_result)\n",
    "                    if empty_count < 3:\n",
    "                        print(prefix + \" || \".join(row_str))\n",
    "\n",
    "    source_df[\"input\"] = \"source\"\n",
    "    bin_df[\"input\"] = \"bin\"\n",
    "\n",
    "    final_df = pd.concat([source_df, bin_df])\n",
    "\n",
    "    display_table(final_df, \"FINAL TABLE\")\n",
    "\n",
    "\n",
    "def display_path_version_tables_latex(source_df: pd.DataFrame, bin_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Pretty-prints two final tables (source vs bin), grouped by directory and solidity version.\n",
    "    \"\"\"\n",
    "\n",
    "    def display_table(df: pd.DataFrame):\n",
    "        lines = []\n",
    "        for directory in sorted(df['directory'].unique()):\n",
    "            dir_df = df[df['directory'] == directory]\n",
    "            path = f\"{{Path: {directory} - N={int(max(dir_df['Count'].unique()))}}}\"\n",
    "            lines.append(f\"\\\\multicolumn{{20}}{{c}}{{\\\\textbf{path}}} \\n\\\\\\\\\\\\midrule\")\n",
    "            for tool in sorted(dir_df[\"toolid\"].unique()):\n",
    "                for input_type in sorted(dir_df[\"input\"].unique()):\n",
    "                    row_str = []\n",
    "                    prefix = f\"{tool} & {input_type[0]}\"\n",
    "                    tool_df = dir_df[(dir_df['toolid'] == tool) & (dir_df['input'] == input_type)]\n",
    "                    empty_count = 0\n",
    "                    for version in sorted(dir_df['solidity_version'].unique()):\n",
    "                        version_df = tool_df[tool_df['solidity_version'] == version]\n",
    "                        if version_df.empty:\n",
    "                            empty_count += 1\n",
    "                            version_result = f\" - & - & - & - & - & -\"\n",
    "                        else:\n",
    "                            row = version_df.iloc[0]\n",
    "                            version_result = f\"{row['Accuracy']:.2f} & {int(row['TP'])} & {int(row['TN'])} & {int(row['FP'])} & {int(row['FN'])} & {int(row['Fails'])}\"\n",
    "                        row_str.append(version_result)\n",
    "                    if empty_count < 3:\n",
    "                        lines.append(prefix + \" & \" + \" & \".join(row_str) + \"\\\\\\\\\")\n",
    "            lines.append(\"\\\\midrule[\\\\heavyrulewidth]\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"% -----------\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        with open('table.tex', 'w') as f:\n",
    "            for line in lines:\n",
    "                f.write(f\"{line}\\n\")\n",
    "\n",
    "    source_df[\"input\"] = \"source\"\n",
    "    bin_df[\"input\"] = \"bin\"\n",
    "\n",
    "    final_df = pd.concat([source_df, bin_df])\n",
    "\n",
    "    display_table(final_df)\n",
    "\n",
    "def display_path_version_tables_latex_new(source_df: pd.DataFrame, bin_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Pretty-prints two final tables (source vs bin), grouped by directory and solidity version.\n",
    "    \"\"\"\n",
    "\n",
    "    def display_table(df: pd.DataFrame):\n",
    "        lines = []\n",
    "\n",
    "        for version in sorted(df['solidity_version'].unique()):\n",
    "            version_df = df[df['solidity_version'] == version]\n",
    "            version = f\"{{Solidity version: {version}}}\"\n",
    "            lines.append(f\"\\\\multicolumn{{20}}{{c}}{{\\\\textbf{version}}} \\n\\\\\\\\\\\\midrule\")\n",
    "            lines.append(\" | \".join(sorted(version_df['directory'].unique())))\n",
    "            for tool in sorted(version_df[\"toolid\"].unique()):\n",
    "                for input_type in sorted(version_df[\"input\"].unique()):\n",
    "                    tool_df = version_df[(version_df['toolid'] == tool) & (version_df['input'] == input_type)]\n",
    "                    tool_str = f\"{{Tool: {tool} ({input_type})}}\"\n",
    "                    if tool_df.empty:\n",
    "                        continue\n",
    "                    row_str = []\n",
    "                    for directory in sorted(version_df['directory'].unique()):\n",
    "                        dir_df = tool_df[tool_df['directory'] == directory]\n",
    "                        if dir_df.empty:\n",
    "                            dir_result = \"-\"\n",
    "                        else:\n",
    "                            row = dir_df.iloc[0]\n",
    "                            dir_result = row['Accuracy']\n",
    "                            if dir_result == 1:\n",
    "                                dir_result = \"V\"\n",
    "                            elif dir_result == 0:\n",
    "                                dir_result = \"X\"\n",
    "                            else:\n",
    "                                dir_result = \"~V\"\n",
    "                        row_str.append(dir_result)\n",
    "                    lines.append(tool_str + \" & \" + \" & \".join(row_str) + \"\\\\\\\\\")\n",
    "            lines.append(\"\\\\midrule[\\\\heavyrulewidth]\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"% -----------\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        with open('table_new.tex', 'w') as f:\n",
    "            for line in lines:\n",
    "                f.write(f\"{line}\\n\")\n",
    "\n",
    "    source_df[\"input\"] = \"source\"\n",
    "    bin_df[\"input\"] = \"bin\"\n",
    "\n",
    "    final_df = pd.concat([source_df, bin_df])\n",
    "\n",
    "    display_table(final_df)\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_data = []\n",
    "    for input_file in INPUT_FILES:\n",
    "        filename_parts = str(input_file).split(\"_\")\n",
    "        version = \".\".join([filename_parts[2]] + [filename_parts[3]])\n",
    "        data_type = filename_parts[4].split(\".\")[0]\n",
    "        print(\"\\n\\n\")\n",
    "        log(\"=\" * 50)\n",
    "        log(f\"Processing input file: {input_file}\")\n",
    "        log(\"=\" * 50)\n",
    "        df = load_and_prepare_data(input_file, COLUMNS_TO_USE)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        df = add_predictions(df, REENTRANCY_LABELS)\n",
    "        df[\"solidity_version\"] = version\n",
    "        df[\"type\"] = data_type\n",
    "        all_data.append(df)\n",
    "\n",
    "    if not all_data:\n",
    "        log(\"No data loaded. Exiting.\", level=\"ERROR\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Existing reports\n",
    "    # calculate_and_display_metrics(combined_df)\n",
    "\n",
    "    # NEW: Path + Solidity version tables (source/bin separated)\n",
    "    source_df, bin_df = calculate_metrics_by_path_and_version(combined_df)\n",
    "    # display_path_version_tables(source_df, bin_df)\n",
    "    display_path_version_tables_latex_new(source_df, bin_df)\n"
   ],
   "id": "dac981186c06d380",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:34:05.392447Z",
     "start_time": "2025-09-07T14:34:03.972672Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "41069c02b1d7d0e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[INFO] [2025-09-07 16:34:03] ==================================================\n",
      "[INFO] [2025-09-07 16:34:03] Processing input file: results_handcrafted_0_8_source_llm.csv\n",
      "[INFO] [2025-09-07 16:34:03] ==================================================\n",
      "[INFO] [2025-09-07 16:34:03] Loading data...\n",
      "[INFO] [2025-09-07 16:34:03] --> Reading 'results_handcrafted_0_8_source_llm.csv'\n",
      "\n",
      "\n",
      "\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Processing input file: results_handcrafted_0_8_source.csv\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Loading data...\n",
      "[INFO] [2025-09-07 16:34:04] --> Reading 'results_handcrafted_0_8_source.csv'\n",
      "\n",
      "\n",
      "\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Processing input file: results_handcrafted_0_5_source.csv\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Loading data...\n",
      "[INFO] [2025-09-07 16:34:04] --> Reading 'results_handcrafted_0_5_source.csv'\n",
      "\n",
      "\n",
      "\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Processing input file: results_handcrafted_0_4_source.csv\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Loading data...\n",
      "[INFO] [2025-09-07 16:34:04] --> Reading 'results_handcrafted_0_4_source.csv'\n",
      "\n",
      "\n",
      "\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Processing input file: results_handcrafted_0_8_bin.csv\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Loading data...\n",
      "[INFO] [2025-09-07 16:34:04] --> Reading 'results_handcrafted_0_8_bin.csv'\n",
      "\n",
      "\n",
      "\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Processing input file: results_handcrafted_0_5_bin.csv\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Loading data...\n",
      "[INFO] [2025-09-07 16:34:04] --> Reading 'results_handcrafted_0_5_bin.csv'\n",
      "\n",
      "\n",
      "\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Processing input file: results_handcrafted_0_4_bin.csv\n",
      "[INFO] [2025-09-07 16:34:04] ==================================================\n",
      "[INFO] [2025-09-07 16:34:04] Loading data...\n",
      "[INFO] [2025-09-07 16:34:04] --> Reading 'results_handcrafted_0_4_bin.csv'\n"
     ]
    }
   ],
   "execution_count": 139
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
