{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-27T08:58:37.306409Z",
     "start_time": "2025-05-27T08:58:36.901500Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def analyze_csv_data_per_tool(df_input):\n",
    "    \"\"\"\n",
    "    Parses CSV data from a pandas DataFrame, filters data, determines ground truth\n",
    "    and predictions for Reentrancy-related findings, handles multiple runs, and\n",
    "    calculates performance metrics per toolid using sklearn.\n",
    "\n",
    "    Args:\n",
    "        df_input (pd.DataFrame): Input DataFrame from CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are toolids and values are dictionaries\n",
    "              containing calculated metrics (accuracy, precision, recall, f1_score)\n",
    "              and counts (TP, FP, TN, FN) for that tool.\n",
    "    \"\"\"\n",
    "    df = df_input.copy() # Work on a copy\n",
    "\n",
    "    # --- Global Preprocessing on df (before splitting by tool) ---\n",
    "\n",
    "    # 2. Determine ground truth ('actual_label') and filter ambiguous filenames\n",
    "    def determine_ground_truth(filename_val):\n",
    "        if isinstance(filename_val, str):\n",
    "            filename_lower = filename_val.lower()\n",
    "            if \"ree\" in filename_lower: # Assumes \"ree\" in filename indicates a vulnerable sample\n",
    "                return 1\n",
    "            if \"safe\" in filename_lower: # Assumes \"safe\" in filename indicates a non-vulnerable sample\n",
    "                return 0\n",
    "        return pd.NA # For filenames not matching 'ree' or 'safe', or if not a string\n",
    "\n",
    "    df['actual_label'] = df['filename'].apply(determine_ground_truth)\n",
    "\n",
    "    original_row_count_before_gt_filter = len(df)\n",
    "    df = df.dropna(subset=['actual_label']) # Remove rows with pd.NA actual_label\n",
    "    print(f\"Filtered out {original_row_count_before_gt_filter - len(df)} rows with ambiguous filenames (not containing 'ree' or 'safe').\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Warning: DataFrame is empty after filtering for 'ree'/'safe' filenames. No data to process.\")\n",
    "        return {}\n",
    "    df['actual_label'] = df['actual_label'].astype(int)\n",
    "\n",
    "    required_columns_for_core_logic = ['filename', 'findings', 'toolid', 'actual_label']\n",
    "    for col in required_columns_for_core_logic:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Critical Error: Column '{col}' is missing after initial processing. Cannot proceed.\")\n",
    "            return {}\n",
    "\n",
    "    results_per_tool = {}\n",
    "    if 'toolid' not in df.columns:\n",
    "        print(\"Critical Error: 'toolid' column is missing. Cannot group results.\")\n",
    "        return {}\n",
    "\n",
    "    unique_toolids = df['toolid'].unique()\n",
    "\n",
    "    for tool_id in unique_toolids:\n",
    "        tool_df_initial = df[df['toolid'] == tool_id].copy()\n",
    "\n",
    "        if tool_df_initial.empty:\n",
    "            continue\n",
    "\n",
    "        tool_df_deduplicated = pd.DataFrame()\n",
    "        if 'start' in tool_df_initial.columns:\n",
    "            tool_df_initial['start_numeric'] = pd.to_numeric(tool_df_initial['start'], errors='coerce')\n",
    "            valid_start_times_df = tool_df_initial.dropna(subset=['start_numeric'])\n",
    "\n",
    "            if not valid_start_times_df.empty:\n",
    "                tool_df_sorted = valid_start_times_df.sort_values(\n",
    "                    by=['filename', 'start_numeric'], ascending=[True, False]\n",
    "                )\n",
    "                tool_df_deduplicated = tool_df_sorted.drop_duplicates(subset=['filename'], keep='first')\n",
    "                print(f\"For toolid '{tool_id}', processed {len(tool_df_initial)} rows initially, kept {len(tool_df_deduplicated)} after deduplicating by filename (latest run with valid start time).\")\n",
    "            else:\n",
    "                print(f\"Warning: For toolid '{tool_id}', no valid numeric 'start' times. Using all {len(tool_df_initial)} rows, which might include duplicates.\")\n",
    "                tool_df_deduplicated = tool_df_initial\n",
    "        else:\n",
    "            print(f\"Warning: 'start' column not found for toolid '{tool_id}'. Using all {len(tool_df_initial)} rows, which might include duplicates.\")\n",
    "            tool_df_deduplicated = tool_df_initial\n",
    "\n",
    "        if tool_df_deduplicated.empty:\n",
    "            print(f\"Warning: No data remaining for toolid '{tool_id}' after deduplication. Skipping.\")\n",
    "            results_per_tool[tool_id] = {\n",
    "                \"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0,\n",
    "                \"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0,\n",
    "                \"error\": \"No data after deduplication\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        tool_df = tool_df_deduplicated\n",
    "        y_true = tool_df['actual_label'].tolist()\n",
    "\n",
    "        # !!! CRITICAL USER ATTENTION POINT !!!\n",
    "        # Define keywords for reentrancy-related findings (case-insensitive).\n",
    "        # This list is crucial and MUST be updated based on how YOUR tools report reentrancy.\n",
    "        reentrancy_keywords = [\n",
    "            \"reentrancy\",       # Broadly catches most reentrancy mentions including specific types like _eth, _no_eth, _events, _benign, _unlimited_gas\n",
    "            \"re-entrancy\",      # Variation\n",
    "            \"reentrant\",        # Adjective form\n",
    "            \"swc_107\",          # Standard Reentrancy SWC ID (will catch SWC-107 too due to .lower())\n",
    "            \"swc-107\",          # Explicitly include hyphenated version for clarity\n",
    "            \"state_access_after_external_call\", # Common pattern from Mythril indicating reentrancy (often with SWC_107)\n",
    "            \"delegatecall\",     # Catches findings like \"Delegatecall_to_user_supplied_address...\" and \"controlled_delegatecall\"\n",
    "            \"swc_112\",          # SWC ID for Delegatecall issues, often a reentrancy vector\n",
    "            \"swc-112\"           # Hyphenated version\n",
    "        ]\n",
    "        tool_df.loc[:, 'predicted_label'] = tool_df['findings'].apply(\n",
    "            lambda x: 1 if isinstance(x, str) and (\"reentrancy_benign\" not in x.lower()) and (any(keyword in x.lower() for keyword in reentrancy_keywords)) else 0\n",
    "        )\n",
    "        y_pred = tool_df['predicted_label'].tolist()\n",
    "\n",
    "        if not y_true:\n",
    "            print(f\"Warning: No valid labels collected for toolid '{tool_id}'. Skipping metrics.\")\n",
    "            results_per_tool[tool_id] = {\n",
    "                \"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0,\n",
    "                \"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0,\n",
    "                \"error\": \"No valid labels after processing\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not compute confusion matrix directly for toolid '{tool_id}': {e}. Manually calculating.\")\n",
    "            tp = sum((yt == 1 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "            fp = sum((yt == 0 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "            tn = sum((yt == 0 and yp == 0) for yt, yp in zip(y_true, y_pred))\n",
    "            fn = sum((yt == 1 and yp == 0) for yt, yp in zip(y_true, y_pred))\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0, labels=[0,1], pos_label=1)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0, labels=[0,1], pos_label=1)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0, labels=[0,1], pos_label=1)\n",
    "\n",
    "        results_per_tool[tool_id] = {\n",
    "            \"tp\": int(tp), \"fp\": int(fp), \"tn\": int(tn), \"fn\": int(fn),\n",
    "            \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1\n",
    "        }\n",
    "    return results_per_tool\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # csv_file_path = \"results_handcrafted.csv\" # Make sure this file exists in the same directory\n",
    "    # df_main = pd.read_csv(csv_file_path)\n",
    "    # print(f\"Successfully loaded '{csv_file_path}', shape: {df_main.shape}\")\n",
    "\n",
    "    df_safe = pd.read_csv(\"results_safe.csv\")\n",
    "    df_reentrant = pd.read_csv(\"results_reentrant.csv\")\n",
    "    df_main = pd.concat([df_reentrant, df_safe], ignore_index=True)\n",
    "\n",
    "    if not df_main.empty:\n",
    "        print(\"\\nAnalyzing CSV data for Reentrancy-related findings per tool (using pandas & sklearn):\\n\")\n",
    "        all_results = analyze_csv_data_per_tool(df_main)\n",
    "\n",
    "        if not all_results:\n",
    "            print(\"No results were generated. Please check the input data and logs.\")\n",
    "        else:\n",
    "            for tool_id, metrics in all_results.items():\n",
    "                print(f\"\\nResults for toolid: {tool_id}\")\n",
    "                if \"error\" in metrics:\n",
    "                    print(f\"  Message: {metrics['error']}\")\n",
    "                elif all(k in metrics for k in [\"tp\", \"fp\", \"tn\", \"fn\"]): # Check if full metrics dict\n",
    "                    print(f\"  True Positives (TP):  {metrics['tp']}\")\n",
    "                    print(f\"  False Positives (FP): {metrics['fp']}\")\n",
    "                    print(f\"  True Negatives (TN):  {metrics['tn']}\")\n",
    "                    print(f\"  False Negatives (FN): {metrics['fn']}\")\n",
    "                    print(\"  ------------------------------------\")\n",
    "                    print(f\"  Accuracy:             {metrics['accuracy']:.4f}\")\n",
    "                    print(f\"  Precision:            {metrics['precision']:.4f}\")\n",
    "                    print(f\"  Recall (Sensitivity): {metrics['recall']:.4f}\")\n",
    "                    print(f\"  F1-Score:             {metrics['f1_score']:.4f}\")\n",
    "                else:\n",
    "                    print(f\"  Metrics data incomplete: {metrics}\")\n",
    "                print(\"-\" * 40)\n",
    "    else:\n",
    "        print(\"Could not proceed with analysis as DataFrame is empty (either file not found/error or dummy data creation failed).\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing CSV data for Reentrancy-related findings per tool (using pandas & sklearn):\n",
      "\n",
      "Filtered out 0 rows with ambiguous filenames (not containing 'ree' or 'safe').\n",
      "For toolid 'confuzzius', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'conkas', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'honeybadger', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'maian', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'manticore-0.3.7', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'mythril-0.24.7', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'osiris', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'oyente', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'securify', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'semgrep', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'sfuzz', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'slither-0.10.4', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'smartcheck', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "For toolid 'solhint-3.3.8', processed 432 rows initially, kept 432 after deduplicating by filename (latest run with valid start time).\n",
      "\n",
      "Results for toolid: confuzzius\n",
      "  True Positives (TP):  75\n",
      "  False Positives (FP): 5\n",
      "  True Negatives (TN):  307\n",
      "  False Negatives (FN): 45\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.8843\n",
      "  Precision:            0.9375\n",
      "  Recall (Sensitivity): 0.6250\n",
      "  F1-Score:             0.7500\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: conkas\n",
      "  True Positives (TP):  90\n",
      "  False Positives (FP): 46\n",
      "  True Negatives (TN):  266\n",
      "  False Negatives (FN): 30\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.8241\n",
      "  Precision:            0.6618\n",
      "  Recall (Sensitivity): 0.7500\n",
      "  F1-Score:             0.7031\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: honeybadger\n",
      "  True Positives (TP):  0\n",
      "  False Positives (FP): 0\n",
      "  True Negatives (TN):  312\n",
      "  False Negatives (FN): 120\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7222\n",
      "  Precision:            0.0000\n",
      "  Recall (Sensitivity): 0.0000\n",
      "  F1-Score:             0.0000\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: maian\n",
      "  True Positives (TP):  0\n",
      "  False Positives (FP): 0\n",
      "  True Negatives (TN):  312\n",
      "  False Negatives (FN): 120\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7222\n",
      "  Precision:            0.0000\n",
      "  Recall (Sensitivity): 0.0000\n",
      "  F1-Score:             0.0000\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: manticore-0.3.7\n",
      "  True Positives (TP):  0\n",
      "  False Positives (FP): 0\n",
      "  True Negatives (TN):  312\n",
      "  False Negatives (FN): 120\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7222\n",
      "  Precision:            0.0000\n",
      "  Recall (Sensitivity): 0.0000\n",
      "  F1-Score:             0.0000\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: mythril-0.24.7\n",
      "  True Positives (TP):  37\n",
      "  False Positives (FP): 24\n",
      "  True Negatives (TN):  288\n",
      "  False Negatives (FN): 83\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7523\n",
      "  Precision:            0.6066\n",
      "  Recall (Sensitivity): 0.3083\n",
      "  F1-Score:             0.4088\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: osiris\n",
      "  True Positives (TP):  42\n",
      "  False Positives (FP): 13\n",
      "  True Negatives (TN):  299\n",
      "  False Negatives (FN): 78\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7894\n",
      "  Precision:            0.7636\n",
      "  Recall (Sensitivity): 0.3500\n",
      "  F1-Score:             0.4800\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: oyente\n",
      "  True Positives (TP):  0\n",
      "  False Positives (FP): 0\n",
      "  True Negatives (TN):  312\n",
      "  False Negatives (FN): 120\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7222\n",
      "  Precision:            0.0000\n",
      "  Recall (Sensitivity): 0.0000\n",
      "  F1-Score:             0.0000\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: securify\n",
      "  True Positives (TP):  0\n",
      "  False Positives (FP): 0\n",
      "  True Negatives (TN):  312\n",
      "  False Negatives (FN): 120\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7222\n",
      "  Precision:            0.0000\n",
      "  Recall (Sensitivity): 0.0000\n",
      "  F1-Score:             0.0000\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: semgrep\n",
      "  True Positives (TP):  1\n",
      "  False Positives (FP): 0\n",
      "  True Negatives (TN):  312\n",
      "  False Negatives (FN): 119\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7245\n",
      "  Precision:            1.0000\n",
      "  Recall (Sensitivity): 0.0083\n",
      "  F1-Score:             0.0165\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: sfuzz\n",
      "  True Positives (TP):  32\n",
      "  False Positives (FP): 15\n",
      "  True Negatives (TN):  297\n",
      "  False Negatives (FN): 88\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7616\n",
      "  Precision:            0.6809\n",
      "  Recall (Sensitivity): 0.2667\n",
      "  F1-Score:             0.3832\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: slither-0.10.4\n",
      "  True Positives (TP):  77\n",
      "  False Positives (FP): 17\n",
      "  True Negatives (TN):  295\n",
      "  False Negatives (FN): 43\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.8611\n",
      "  Precision:            0.8191\n",
      "  Recall (Sensitivity): 0.6417\n",
      "  F1-Score:             0.7196\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: smartcheck\n",
      "  True Positives (TP):  0\n",
      "  False Positives (FP): 0\n",
      "  True Negatives (TN):  312\n",
      "  False Negatives (FN): 120\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.7222\n",
      "  Precision:            0.0000\n",
      "  Recall (Sensitivity): 0.0000\n",
      "  F1-Score:             0.0000\n",
      "----------------------------------------\n",
      "\n",
      "Results for toolid: solhint-3.3.8\n",
      "  True Positives (TP):  43\n",
      "  False Positives (FP): 6\n",
      "  True Negatives (TN):  306\n",
      "  False Negatives (FN): 77\n",
      "  ------------------------------------\n",
      "  Accuracy:             0.8079\n",
      "  Precision:            0.8776\n",
      "  Recall (Sensitivity): 0.3583\n",
      "  F1-Score:             0.5089\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
